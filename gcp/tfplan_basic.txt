
Terraform used the selected providers to generate the following execution
plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # google_compute_address.nat_egress_ip will be created
  + resource "google_compute_address" "nat_egress_ip" {
      + address            = (known after apply)
      + address_type       = "EXTERNAL"
      + creation_timestamp = (known after apply)
      + id                 = (known after apply)
      + name               = (known after apply)
      + network_tier       = (known after apply)
      + prefix_length      = (known after apply)
      + project            = (known after apply)
      + purpose            = (known after apply)
      + region             = "us-central1"
      + self_link          = (known after apply)
      + subnetwork         = (known after apply)
      + users              = (known after apply)
    }

  # google_compute_firewall.allow-internal will be created
  + resource "google_compute_firewall" "allow-internal" {
      + creation_timestamp = (known after apply)
      + destination_ranges = (known after apply)
      + direction          = (known after apply)
      + enable_logging     = (known after apply)
      + id                 = (known after apply)
      + name               = (known after apply)
      + network            = (known after apply)
      + priority           = 1000
      + project            = (known after apply)
      + self_link          = (known after apply)
      + source_ranges      = [
          + "10.131.0.0/20",
        ]

      + allow {
          + ports    = [
              + "80-65535",
            ]
          + protocol = "tcp"
        }
      + allow {
          + ports    = [
              + "80-65535",
            ]
          + protocol = "udp"
        }
      + allow {
          + ports    = []
          + protocol = "icmp"
        }
    }

  # google_compute_firewall.allow-ssh will be created
  + resource "google_compute_firewall" "allow-ssh" {
      + creation_timestamp = (known after apply)
      + destination_ranges = (known after apply)
      + direction          = (known after apply)
      + enable_logging     = (known after apply)
      + id                 = (known after apply)
      + name               = (known after apply)
      + network            = (known after apply)
      + priority           = 1000
      + project            = (known after apply)
      + self_link          = (known after apply)
      + source_ranges      = [
          + "35.235.240.0/20",
        ]
      + target_tags        = [
          + "bastion",
        ]

      + allow {
          + ports    = [
              + "22",
            ]
          + protocol = "tcp"
        }
    }

  # google_compute_global_address.gce_ingress_ip will be created
  + resource "google_compute_global_address" "gce_ingress_ip" {
      + address            = (known after apply)
      + creation_timestamp = (known after apply)
      + id                 = (known after apply)
      + name               = (known after apply)
      + prefix_length      = (known after apply)
      + project            = "formidable-pact-398819"
      + self_link          = (known after apply)
    }

  # google_compute_instance.bastion[0] will be created
  + resource "google_compute_instance" "bastion" {
      + can_ip_forward          = false
      + cpu_platform            = (known after apply)
      + current_status          = (known after apply)
      + deletion_protection     = false
      + guest_accelerator       = (known after apply)
      + id                      = (known after apply)
      + instance_id             = (known after apply)
      + label_fingerprint       = (known after apply)
      + machine_type            = "e2-standard-2"
      + metadata                = {
          + "block-project-ssh-keys" = "true"
        }
      + metadata_fingerprint    = (known after apply)
      + metadata_startup_script = <<-EOT
            #!/bin/bash
            sudo apt-get update
            # Install kubectl
            sudo apt-get install -y apt-transport-https ca-certificates curl
            sudo mkdir -p /etc/apt/keyrings/
            curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
            echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list
            # Install gcloud-sdk
            sudo snap remove google-cloud-cli
            echo "deb [signed-by=/usr/share/keyrings/cloud.google.asc] https://packages.cloud.google.com/apt cloud-sdk main" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
            curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo tee /usr/share/keyrings/cloud.google.asc
            sudo apt-get update && sudo apt-get install -y google-cloud-cli kubectl google-cloud-cli-gke-gcloud-auth-plugin gnupg software-properties-common
            # Install terraform
            wget -O- https://apt.releases.hashicorp.com/gpg | gpg --dearmor | sudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpg
            echo "deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] \
            https://apt.releases.hashicorp.com $(lsb_release -cs) main" | \
            sudo tee /etc/apt/sources.list.d/hashicorp.list
            sudo apt update && sudo apt-get install -y terraform tinyproxy
            sudo sed -i "225i Allow localhost" /etc/tinyproxy/tinyproxy.conf
            sudo systemctl restart tinyproxy.service
        EOT
      + min_cpu_platform        = (known after apply)
      + name                    = (known after apply)
      + project                 = (known after apply)
      + self_link               = (known after apply)
      + tags                    = [
          + "bastion",
        ]
      + tags_fingerprint        = (known after apply)
      + zone                    = "us-central1-a"

      + boot_disk {
          + auto_delete                = true
          + device_name                = (known after apply)
          + disk_encryption_key_sha256 = (known after apply)
          + kms_key_self_link          = (known after apply)
          + mode                       = "READ_WRITE"
          + source                     = (known after apply)

          + initialize_params {
              + image  = "ubuntu-2004-focal-v20230918"
              + labels = (known after apply)
              + size   = (known after apply)
              + type   = (known after apply)
            }
        }

      + network_interface {
          + internal_ipv6_prefix_length = (known after apply)
          + ipv6_access_type            = (known after apply)
          + ipv6_address                = (known after apply)
          + name                        = (known after apply)
          + network                     = (known after apply)
          + network_ip                  = (known after apply)
          + stack_type                  = (known after apply)
          + subnetwork                  = (known after apply)
          + subnetwork_project          = (known after apply)
        }

      + service_account {
          + email  = (known after apply)
          + scopes = [
              + "https://www.googleapis.com/auth/cloud-platform",
            ]
        }

      + shielded_instance_config {
          + enable_integrity_monitoring = true
          + enable_secure_boot          = false
          + enable_vtpm                 = true
        }
    }

  # google_compute_network.network will be created
  + resource "google_compute_network" "network" {
      + auto_create_subnetworks                   = false
      + delete_default_routes_on_create           = false
      + gateway_ipv4                              = (known after apply)
      + id                                        = (known after apply)
      + internal_ipv6_range                       = (known after apply)
      + mtu                                       = (known after apply)
      + name                                      = (known after apply)
      + network_firewall_policy_enforcement_order = "AFTER_CLASSIC_FIREWALL"
      + project                                   = "formidable-pact-398819"
      + routing_mode                              = (known after apply)
      + self_link                                 = (known after apply)
    }

  # google_compute_router.router will be created
  + resource "google_compute_router" "router" {
      + creation_timestamp = (known after apply)
      + id                 = (known after apply)
      + name               = (known after apply)
      + network            = (known after apply)
      + project            = (known after apply)
      + region             = "us-central1"
      + self_link          = (known after apply)
    }

  # google_compute_router_nat.nat_manual will be created
  + resource "google_compute_router_nat" "nat_manual" {
      + enable_dynamic_port_allocation      = (known after apply)
      + enable_endpoint_independent_mapping = true
      + icmp_idle_timeout_sec               = 30
      + id                                  = (known after apply)
      + min_ports_per_vm                    = 64
      + name                                = (known after apply)
      + nat_ip_allocate_option              = "MANUAL_ONLY"
      + nat_ips                             = (known after apply)
      + project                             = (known after apply)
      + region                              = "us-central1"
      + router                              = (known after apply)
      + source_subnetwork_ip_ranges_to_nat  = "ALL_SUBNETWORKS_ALL_IP_RANGES"
      + tcp_established_idle_timeout_sec    = 1200
      + tcp_time_wait_timeout_sec           = 120
      + tcp_transitory_idle_timeout_sec     = 30
      + udp_idle_timeout_sec                = 30

      + log_config {
          + enable = true
          + filter = "ERRORS_ONLY"
        }
    }

  # google_compute_subnetwork.subnetwork will be created
  + resource "google_compute_subnetwork" "subnetwork" {
      + creation_timestamp         = (known after apply)
      + external_ipv6_prefix       = (known after apply)
      + fingerprint                = (known after apply)
      + gateway_address            = (known after apply)
      + id                         = (known after apply)
      + ip_cidr_range              = "10.131.0.0/20"
      + ipv6_cidr_range            = (known after apply)
      + name                       = (known after apply)
      + network                    = (known after apply)
      + private_ip_google_access   = true
      + private_ipv6_google_access = (known after apply)
      + project                    = "formidable-pact-398819"
      + purpose                    = (known after apply)
      + region                     = "us-central1"
      + secondary_ip_range         = (known after apply)
      + self_link                  = (known after apply)
      + stack_type                 = (known after apply)

      + log_config {
          + aggregation_interval = "INTERVAL_15_MIN"
          + filter_expr          = "true"
          + flow_sampling        = 0.1
          + metadata             = "INCLUDE_ALL_METADATA"
        }
    }

  # google_container_cluster.logscale_test1 will be created
  + resource "google_container_cluster" "logscale_test1" {
      + cluster_ipv4_cidr           = (known after apply)
      + datapath_provider           = (known after apply)
      + default_max_pods_per_node   = (known after apply)
      + enable_binary_authorization = false
      + enable_fqdn_network_policy  = false
      + enable_intranode_visibility = (known after apply)
      + enable_kubernetes_alpha     = false
      + enable_l4_ilb_subsetting    = false
      + enable_legacy_abac          = false
      + enable_multi_networking     = false
      + enable_shielded_nodes       = true
      + enable_tpu                  = (known after apply)
      + endpoint                    = (known after apply)
      + id                          = (known after apply)
      + initial_node_count          = 1
      + label_fingerprint           = (known after apply)
      + location                    = "us-central1"
      + logging_service             = "logging.googleapis.com/kubernetes"
      + master_version              = (known after apply)
      + min_master_version          = "1.30.3-gke.1639000"
      + monitoring_service          = "monitoring.googleapis.com/kubernetes"
      + name                        = (known after apply)
      + network                     = (known after apply)
      + networking_mode             = (known after apply)
      + node_locations              = (known after apply)
      + node_version                = (known after apply)
      + operation                   = (known after apply)
      + private_ipv6_google_access  = (known after apply)
      + project                     = (known after apply)
      + remove_default_node_pool    = true
      + resource_labels             = {
          + "kubernetescluster" = "logscale"
        }
      + self_link                   = (known after apply)
      + services_ipv4_cidr          = (known after apply)
      + subnetwork                  = (known after apply)
      + tpu_ipv4_cidr_block         = (known after apply)

      + ip_allocation_policy {
          + cluster_ipv4_cidr_block       = "10.124.0.0/14"
          + cluster_secondary_range_name  = (known after apply)
          + services_ipv4_cidr_block      = "172.24.2.0/24"
          + services_secondary_range_name = (known after apply)
          + stack_type                    = "IPV4"
        }

      + maintenance_policy {
          + daily_maintenance_window {
              + duration   = (known after apply)
              + start_time = "05:00"
            }
        }

      + master_auth {
          + client_certificate     = (known after apply)
          + client_key             = (sensitive value)
          + cluster_ca_certificate = (known after apply)

          + client_certificate_config {
              + issue_client_certificate = false
            }
        }

      + master_authorized_networks_config {
          + gcp_public_cidrs_access_enabled = (known after apply)
        }

      + private_cluster_config {
          + enable_private_endpoint = true
          + enable_private_nodes    = true
          + master_ipv4_cidr_block  = "172.24.2.0/28"
          + peering_name            = (known after apply)
          + private_endpoint        = (known after apply)
          + public_endpoint         = (known after apply)
        }

      + release_channel {
          + channel = "UNSPECIFIED"
        }

      + vertical_pod_autoscaling {
          + enabled = false
        }

      + workload_identity_config {
          + workload_pool = "formidable-pact-398819.svc.id.goog"
        }
    }

  # google_container_node_pool.kafka_node_pool_test1 will be created
  + resource "google_container_node_pool" "kafka_node_pool_test1" {
      + cluster                     = (known after apply)
      + id                          = (known after apply)
      + initial_node_count          = (known after apply)
      + instance_group_urls         = (known after apply)
      + location                    = "us-central1"
      + managed_instance_group_urls = (known after apply)
      + max_pods_per_node           = (known after apply)
      + name                        = (known after apply)
      + name_prefix                 = (known after apply)
      + node_count                  = 1
      + node_locations              = (known after apply)
      + operation                   = (known after apply)
      + project                     = (known after apply)
      + version                     = "1.30.3-gke.1639000"

      + autoscaling {
          + location_policy = (known after apply)
          + max_node_count  = 3
          + min_node_count  = 1
        }

      + management {
          + auto_repair  = true
          + auto_upgrade = false
        }

      + node_config {
          + disk_size_gb      = 128
          + disk_type         = "pd-ssd"
          + guest_accelerator = (known after apply)
          + image_type        = "COS_CONTAINERD"
          + labels            = (known after apply)
          + local_ssd_count   = (known after apply)
          + logging_variant   = "DEFAULT"
          + machine_type      = "e2-standard-4"
          + metadata          = {
              + "block-project-ssh-keys" = "true"
            }
          + min_cpu_platform  = (known after apply)
          + oauth_scopes      = [
              + "https://www.googleapis.com/auth/compute",
              + "https://www.googleapis.com/auth/devstorage.read_only",
              + "https://www.googleapis.com/auth/logging.write",
              + "https://www.googleapis.com/auth/monitoring",
            ]
          + preemptible       = false
          + service_account   = (known after apply)
          + spot              = false
          + taint             = (known after apply)
        }

      + timeouts {
          + delete = "1h"
        }
    }

  # google_container_node_pool.logscale_node_pool_test1 will be created
  + resource "google_container_node_pool" "logscale_node_pool_test1" {
      + cluster                     = (known after apply)
      + id                          = (known after apply)
      + initial_node_count          = (known after apply)
      + instance_group_urls         = (known after apply)
      + location                    = "us-central1"
      + managed_instance_group_urls = (known after apply)
      + max_pods_per_node           = (known after apply)
      + name                        = (known after apply)
      + name_prefix                 = (known after apply)
      + node_count                  = 1
      + node_locations              = (known after apply)
      + operation                   = (known after apply)
      + project                     = (known after apply)
      + version                     = "1.30.3-gke.1639000"

      + autoscaling {
          + location_policy = (known after apply)
          + max_node_count  = 3
          + min_node_count  = 1
        }

      + management {
          + auto_repair  = true
          + auto_upgrade = false
        }

      + node_config {
          + disk_size_gb      = 128
          + disk_type         = "pd-ssd"
          + guest_accelerator = (known after apply)
          + image_type        = "COS_CONTAINERD"
          + labels            = (known after apply)
          + local_ssd_count   = (known after apply)
          + logging_variant   = "DEFAULT"
          + machine_type      = "n2-standard-16"
          + metadata          = {
              + "block-project-ssh-keys" = "true"
            }
          + min_cpu_platform  = (known after apply)
          + oauth_scopes      = [
              + "https://www.googleapis.com/auth/compute",
              + "https://www.googleapis.com/auth/devstorage.read_only",
              + "https://www.googleapis.com/auth/logging.write",
              + "https://www.googleapis.com/auth/monitoring",
            ]
          + preemptible       = false
          + service_account   = (known after apply)
          + spot              = false
          + taint             = (known after apply)

          + local_nvme_ssd_block_config {
              + local_ssd_count = 8
            }

          + workload_metadata_config {
              + mode = "GKE_METADATA"
            }
        }

      + timeouts {
          + delete = "1h"
        }
    }

  # google_container_node_pool.zookeeper_node_pool_test1 will be created
  + resource "google_container_node_pool" "zookeeper_node_pool_test1" {
      + cluster                     = (known after apply)
      + id                          = (known after apply)
      + initial_node_count          = (known after apply)
      + instance_group_urls         = (known after apply)
      + location                    = "us-central1"
      + managed_instance_group_urls = (known after apply)
      + max_pods_per_node           = (known after apply)
      + name                        = (known after apply)
      + name_prefix                 = (known after apply)
      + node_count                  = 1
      + node_locations              = (known after apply)
      + operation                   = (known after apply)
      + project                     = (known after apply)
      + version                     = "1.30.3-gke.1639000"

      + autoscaling {
          + location_policy = (known after apply)
          + max_node_count  = 3
          + min_node_count  = 1
        }

      + management {
          + auto_repair  = true
          + auto_upgrade = false
        }

      + node_config {
          + disk_size_gb      = 64
          + disk_type         = "pd-ssd"
          + guest_accelerator = (known after apply)
          + image_type        = "COS_CONTAINERD"
          + labels            = (known after apply)
          + local_ssd_count   = (known after apply)
          + logging_variant   = "DEFAULT"
          + machine_type      = "e2-standard-4"
          + metadata          = {
              + "block-project-ssh-keys" = "true"
            }
          + min_cpu_platform  = (known after apply)
          + oauth_scopes      = [
              + "https://www.googleapis.com/auth/compute",
              + "https://www.googleapis.com/auth/devstorage.read_only",
              + "https://www.googleapis.com/auth/logging.write",
              + "https://www.googleapis.com/auth/monitoring",
            ]
          + preemptible       = false
          + service_account   = (known after apply)
          + spot              = false
          + taint             = (known after apply)
        }

      + timeouts {
          + delete = "1h"
        }
    }

  # google_project_iam_binding.terraform_gcp_sa_editor will be created
  + resource "google_project_iam_binding" "terraform_gcp_sa_editor" {
      + etag    = (known after apply)
      + id      = (known after apply)
      + members = (known after apply)
      + project = "formidable-pact-398819"
      + role    = "roles/editor"
    }

  # google_project_iam_binding.terraform_gcp_sa_roles will be created
  + resource "google_project_iam_binding" "terraform_gcp_sa_roles" {
      + etag    = (known after apply)
      + id      = (known after apply)
      + members = (known after apply)
      + project = "formidable-pact-398819"
      + role    = "roles/storage.objectAdmin"
    }

  # google_service_account.bastion_service_account[0] will be created
  + resource "google_service_account" "bastion_service_account" {
      + account_id   = (known after apply)
      + disabled     = false
      + display_name = "SA for Bastion VM Instance"
      + email        = (known after apply)
      + id           = (known after apply)
      + member       = (known after apply)
      + name         = (known after apply)
      + project      = (known after apply)
      + unique_id    = (known after apply)
    }

  # google_service_account.tf_service_account will be created
  + resource "google_service_account" "tf_service_account" {
      + account_id   = (known after apply)
      + disabled     = false
      + display_name = "Terraform GCP Service Account"
      + email        = (known after apply)
      + id           = (known after apply)
      + member       = (known after apply)
      + name         = (known after apply)
      + project      = (known after apply)
      + unique_id    = (known after apply)
    }

  # google_service_account_iam_binding.gcs_wl_binding will be created
  + resource "google_service_account_iam_binding" "gcs_wl_binding" {
      + etag               = (known after apply)
      + id                 = (known after apply)
      + members            = (known after apply)
      + role               = "roles/iam.workloadIdentityUser"
      + service_account_id = (known after apply)
    }

  # google_storage_bucket.log_bucket will be created
  + resource "google_storage_bucket" "log_bucket" {
      + force_destroy               = false
      + id                          = (known after apply)
      + labels                      = (known after apply)
      + location                    = "US"
      + name                        = (known after apply)
      + project                     = (known after apply)
      + public_access_prevention    = (known after apply)
      + self_link                   = (known after apply)
      + storage_class               = "STANDARD"
      + uniform_bucket_level_access = (known after apply)
      + url                         = (known after apply)
    }

  # google_storage_bucket.logscale_bucket_storage will be created
  + resource "google_storage_bucket" "logscale_bucket_storage" {
      + force_destroy               = false
      + id                          = (known after apply)
      + labels                      = (known after apply)
      + location                    = "US-CENTRAL1"
      + name                        = (known after apply)
      + project                     = (known after apply)
      + public_access_prevention    = (known after apply)
      + self_link                   = (known after apply)
      + storage_class               = "STANDARD"
      + uniform_bucket_level_access = true
      + url                         = (known after apply)

      + lifecycle_rule {
          + action {
              + type = "Delete"
            }
          + condition {
              + days_since_noncurrent_time = 1
              + matches_prefix             = []
              + matches_storage_class      = []
              + matches_suffix             = []
              + with_state                 = (known after apply)
            }
        }

      + logging {
          + log_bucket        = (known after apply)
          + log_object_prefix = "access-logs/"
        }

      + versioning {
          + enabled = true
        }
    }

  # google_storage_bucket_iam_member.members will be created
  + resource "google_storage_bucket_iam_member" "members" {
      + bucket = (known after apply)
      + etag   = (known after apply)
      + id     = (known after apply)
      + member = (known after apply)
      + role   = "roles/storage.objectUser"
    }

  # random_string.env_identifier_rand will be created
  + resource "random_string" "env_identifier_rand" {
      + id          = (known after apply)
      + length      = 4
      + lower       = true
      + min_lower   = 0
      + min_numeric = 0
      + min_special = 0
      + min_upper   = 0
      + number      = true
      + numeric     = true
      + result      = (known after apply)
      + special     = false
      + upper       = false
    }

  # random_string.node_pool_suffix will be created
  + resource "random_string" "node_pool_suffix" {
      + id          = (known after apply)
      + length      = 4
      + lower       = true
      + min_lower   = 0
      + min_numeric = 0
      + min_special = 0
      + min_upper   = 0
      + number      = false
      + numeric     = false
      + result      = (known after apply)
      + special     = false
      + upper       = false
    }

  # module.gcs_workload_identity.google_service_account.cluster_service_account[0] will be created
  + resource "google_service_account" "cluster_service_account" {
      + account_id   = (known after apply)
      + disabled     = false
      + display_name = (known after apply)
      + email        = (known after apply)
      + id           = (known after apply)
      + member       = (known after apply)
      + name         = (known after apply)
      + project      = "formidable-pact-398819"
      + unique_id    = (known after apply)
    }

  # module.gcs_workload_identity.google_service_account_iam_member.main will be created
  + resource "google_service_account_iam_member" "main" {
      + etag               = (known after apply)
      + id                 = (known after apply)
      + member             = (known after apply)
      + role               = "roles/iam.workloadIdentityUser"
      + service_account_id = (known after apply)
    }

Plan: 25 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + bastion_hostname               = (known after apply)
  + bastion_ssh                    = (known after apply)
  + bastion_ssh_proxy              = (known after apply)
  + gce-ingress-external-static-ip = (known after apply)
  + gke_credential_command         = (known after apply)
  + logscale-nat-ip                = (known after apply)
  + logscale_bucket_storage        = (known after apply)
  + logscale_cluster_definitions   = {
      + large  = {
          + kafka_broker_data_disk_size     = "2504Gi"
          + kafka_broker_machine_type       = "n2-standard-16"
          + kafka_broker_max_node_count     = 9
          + kafka_broker_min_node_count     = 3
          + kafka_broker_node_count         = 9
          + kafka_broker_resources          = {
              + limits   = {
                  + cpu    = 15
                  + memory = "60Gi"
                }
              + requests = {
                  + cpu    = 15
                  + memory = "60Gi"
                }
            }
          + kafka_broker_root_disk_size     = 200
          + kafka_broker_root_disk_type     = "pd-ssd"
          + logscale_digest_data_disk_size  = "11500Gi"
          + logscale_digest_local_ssd_count = 32
          + logscale_digest_machine_type    = "n2-standard-32"
          + logscale_digest_max_node_count  = 16
          + logscale_digest_min_node_count  = 14
          + logscale_digest_node_count      = 42
          + logscale_digest_resources       = {
              + limits   = {
                  + cpu    = 30
                  + memory = "120Gi"
                }
              + requests = {
                  + cpu    = 30
                  + memory = "120Gi"
                }
            }
          + logscale_digest_root_disk_size  = 128
          + logscale_digest_root_disk_type  = "pd-ssd"
          + logscale_ingest_data_disk_size  = "128Gi"
          + logscale_ingest_machine_type    = "n2-standard-16"
          + logscale_ingest_max_node_count  = 6
          + logscale_ingest_min_node_count  = 3
          + logscale_ingest_node_count      = 9
          + logscale_ingest_resources       = {
              + limits   = {
                  + cpu    = 15
                  + memory = "30Gi"
                }
              + requests = {
                  + cpu    = 15
                  + memory = "60Gi"
                }
            }
          + logscale_ingest_root_disk_size  = 200
          + logscale_ingest_root_disk_type  = "pd-ssd"
          + logscale_ingress_data_disk_size = "128Gi"
          + logscale_ingress_machine_type   = "n2-standard-16"
          + logscale_ingress_max_node_count = 9
          + logscale_ingress_min_node_count = 6
          + logscale_ingress_node_count     = 18
          + logscale_ingress_resources      = {
              + limits   = {
                  + cpu    = 15
                  + memory = "60Gi"
                }
              + requests = {
                  + cpu    = 15
                  + memory = "60Gi"
                }
            }
          + logscale_ingress_root_disk_size = 128
          + logscale_ingress_root_disk_type = "pd-ssd"
          + logscale_ui_data_disk_size      = "128Gi"
          + logscale_ui_machine_type        = "n2-standard-16"
          + logscale_ui_max_node_count      = 6
          + logscale_ui_min_node_count      = 3
          + logscale_ui_node_count          = 9
          + logscale_ui_resources           = {
              + limits   = {
                  + cpu    = 15
                  + memory = "60Gi"
                }
              + requests = {
                  + cpu    = 7
                  + memory = "60Gi"
                }
            }
          + logscale_ui_root_disk_size      = 128
          + logscale_ui_root_disk_type      = "pd-ssd"
          + zookeeper_data_disk_size        = "64Gi"
          + zookeeper_machine_type          = "e2-standard-4"
          + zookeeper_max_node_count        = 3
          + zookeeper_min_node_count        = 1
          + zookeeper_node_count            = 3
          + zookeeper_resources             = {
              + limits   = {
                  + cpu    = 3
                  + memory = "8Gi"
                }
              + requests = {
                  + cpu    = 1
                  + memory = "8Gi"
                }
            }
          + zookeeper_root_disk_size        = 64
          + zookeeper_root_disk_type        = "pd-ssd"
        }
      + medium = {
          + kafka_broker_data_disk_size     = "1252Gi"
          + kafka_broker_machine_type       = "n2-standard-8"
          + kafka_broker_max_node_count     = 9
          + kafka_broker_min_node_count     = 3
          + kafka_broker_node_count         = 9
          + kafka_broker_resources          = {
              + limits   = {
                  + cpu    = 7
                  + memory = "30Gi"
                }
              + requests = {
                  + cpu    = 7
                  + memory = "30Gi"
                }
            }
          + kafka_broker_root_disk_size     = 200
          + kafka_broker_root_disk_type     = "pd-ssd"
          + logscale_digest_data_disk_size  = "11500Gi"
          + logscale_digest_local_ssd_count = 32
          + logscale_digest_machine_type    = "n2-standard-32"
          + logscale_digest_max_node_count  = 9
          + logscale_digest_min_node_count  = 7
          + logscale_digest_node_count      = 21
          + logscale_digest_resources       = {
              + limits   = {
                  + cpu    = 30
                  + memory = "120Gi"
                }
              + requests = {
                  + cpu    = 30
                  + memory = "120Gi"
                }
            }
          + logscale_digest_root_disk_size  = 128
          + logscale_digest_root_disk_type  = "pd-ssd"
          + logscale_ingest_data_disk_size  = "128Gi"
          + logscale_ingest_machine_type    = "n2-standard-8"
          + logscale_ingest_max_node_count  = 4
          + logscale_ingest_min_node_count  = 2
          + logscale_ingest_node_count      = 6
          + logscale_ingest_resources       = {
              + limits   = {
                  + cpu    = 7
                  + memory = "30Gi"
                }
              + requests = {
                  + cpu    = 7
                  + memory = "30Gi"
                }
            }
          + logscale_ingest_root_disk_size  = 200
          + logscale_ingest_root_disk_type  = "pd-ssd"
          + logscale_ingress_data_disk_size = "128Gi"
          + logscale_ingress_machine_type   = "n2-standard-8"
          + logscale_ingress_max_node_count = 6
          + logscale_ingress_min_node_count = 4
          + logscale_ingress_node_count     = 12
          + logscale_ingress_resources      = {
              + limits   = {
                  + cpu    = 7
                  + memory = "30Gi"
                }
              + requests = {
                  + cpu    = 7
                  + memory = "30Gi"
                }
            }
          + logscale_ingress_root_disk_size = 200
          + logscale_ingress_root_disk_type = "pd-ssd"
          + logscale_ui_data_disk_size      = "128Gi"
          + logscale_ui_machine_type        = "n2-standard-8"
          + logscale_ui_max_node_count      = 4
          + logscale_ui_min_node_count      = 2
          + logscale_ui_node_count          = 6
          + logscale_ui_resources           = {
              + limits   = {
                  + cpu    = 7
                  + memory = "30Gi"
                }
              + requests = {
                  + cpu    = 7
                  + memory = "30Gi"
                }
            }
          + logscale_ui_root_disk_size      = 200
          + logscale_ui_root_disk_type      = "pd-ssd"
          + zookeeper_data_disk_size        = "64Gi"
          + zookeeper_machine_type          = "e2-standard-4"
          + zookeeper_max_node_count        = 3
          + zookeeper_min_node_count        = 1
          + zookeeper_node_count            = 3
          + zookeeper_resources             = {
              + limits   = {
                  + cpu    = 3
                  + memory = "8Gi"
                }
              + requests = {
                  + cpu    = 1
                  + memory = "8Gi"
                }
            }
          + zookeeper_root_disk_size        = 64
          + zookeeper_root_disk_type        = "pd-ssd"
        }
      + small  = {
          + kafka_broker_data_disk_size     = "376Gi"
          + kafka_broker_machine_type       = "e2-standard-4"
          + kafka_broker_max_node_count     = 4
          + kafka_broker_min_node_count     = 2
          + kafka_broker_node_count         = 6
          + kafka_broker_resources          = {
              + limits   = {
                  + cpu    = 3
                  + memory = "10Gi"
                }
              + requests = {
                  + cpu    = 3
                  + memory = "10Gi"
                }
            }
          + kafka_broker_root_disk_size     = 128
          + kafka_broker_root_disk_type     = "pd-ssd"
          + logscale_digest_data_disk_size  = "5800Gi"
          + logscale_digest_local_ssd_count = 16
          + logscale_digest_machine_type    = "n2-standard-8"
          + logscale_digest_max_node_count  = 6
          + logscale_digest_min_node_count  = 3
          + logscale_digest_node_count      = 9
          + logscale_digest_resources       = {
              + limits   = {
                  + cpu    = 7
                  + memory = "28Gi"
                }
              + requests = {
                  + cpu    = 7
                  + memory = "28Gi"
                }
            }
          + logscale_digest_root_disk_size  = 128
          + logscale_digest_root_disk_type  = "pd-ssd"
          + logscale_ingest_data_disk_size  = "128Gi"
          + logscale_ingest_machine_type    = "e2-standard-4"
          + logscale_ingest_max_node_count  = 3
          + logscale_ingest_min_node_count  = 1
          + logscale_ingest_node_count      = 3
          + logscale_ingest_resources       = {
              + limits   = {
                  + cpu    = 3
                  + memory = "12Gi"
                }
              + requests = {
                  + cpu    = 3
                  + memory = "12Gi"
                }
            }
          + logscale_ingest_root_disk_size  = 128
          + logscale_ingest_root_disk_type  = "pd-ssd"
          + logscale_ingress_data_disk_size = "128Gi"
          + logscale_ingress_machine_type   = "e2-standard-4"
          + logscale_ingress_max_node_count = 4
          + logscale_ingress_min_node_count = 2
          + logscale_ingress_node_count     = 6
          + logscale_ingress_resources      = {
              + limits   = {
                  + cpu    = 3
                  + memory = "12Gi"
                }
              + requests = {
                  + cpu    = 3
                  + memory = "12Gi"
                }
            }
          + logscale_ingress_root_disk_size = 128
          + logscale_ingress_root_disk_type = "pd-ssd"
          + logscale_ui_data_disk_size      = "128Gi"
          + logscale_ui_machine_type        = "e2-standard-4"
          + logscale_ui_max_node_count      = 3
          + logscale_ui_min_node_count      = 1
          + logscale_ui_node_count          = 3
          + logscale_ui_resources           = {
              + limits   = {
                  + cpu    = 3
                  + memory = "12Gi"
                }
              + requests = {
                  + cpu    = 3
                  + memory = "12Gi"
                }
            }
          + logscale_ui_root_disk_size      = 128
          + logscale_ui_root_disk_type      = "pd-ssd"
          + zookeeper_data_disk_size        = "64Gi"
          + zookeeper_machine_type          = "e2-standard-4"
          + zookeeper_max_node_count        = 3
          + zookeeper_min_node_count        = 1
          + zookeeper_node_count            = 3
          + zookeeper_resources             = {
              + limits   = {
                  + cpu    = 3
                  + memory = "8Gi"
                }
              + requests = {
                  + cpu    = 1
                  + memory = "8Gi"
                }
            }
          + zookeeper_root_disk_size        = 64
          + zookeeper_root_disk_type        = "pd-ssd"
        }
      + xlarge = {
          + kafka_broker_data_disk_size     = "2504Gi"
          + kafka_broker_machine_type       = "n2-standard-16"
          + kafka_broker_max_node_count     = 9
          + kafka_broker_min_node_count     = 3
          + kafka_broker_node_count         = 18
          + kafka_broker_resources          = {
              + limits   = {
                  + cpu    = 15
                  + memory = "60Gi"
                }
              + requests = {
                  + cpu    = 15
                  + memory = "60Gi"
                }
            }
          + kafka_broker_root_disk_size     = 200
          + kafka_broker_root_disk_type     = "pd-ssd"
          + logscale_digest_data_disk_size  = "11500Gi"
          + logscale_digest_local_ssd_count = 32
          + logscale_digest_machine_type    = "n2-standard-48"
          + logscale_digest_max_node_count  = 28
          + logscale_digest_min_node_count  = 26
          + logscale_digest_node_count      = 78
          + logscale_digest_resources       = {
              + limits   = {
                  + cpu    = 46
                  + memory = "184Gi"
                }
              + requests = {
                  + cpu    = 46
                  + memory = "184Gi"
                }
            }
          + logscale_digest_root_disk_size  = 128
          + logscale_digest_root_disk_type  = "pd-ssd"
          + logscale_ingest_data_disk_size  = "128Gi"
          + logscale_ingest_machine_type    = "n2-standard-16"
          + logscale_ingest_max_node_count  = 6
          + logscale_ingest_min_node_count  = 3
          + logscale_ingest_node_count      = 9
          + logscale_ingest_resources       = {
              + limits   = {
                  + cpu    = 30
                  + memory = "122Gi"
                }
              + requests = {
                  + cpu    = 30
                  + memory = "122Gi"
                }
            }
          + logscale_ingest_root_disk_size  = 200
          + logscale_ingest_root_disk_type  = "pd-ssd"
          + logscale_ingress_data_disk_size = "128Gi"
          + logscale_ingress_machine_type   = "n2-standard-16"
          + logscale_ingress_max_node_count = 9
          + logscale_ingress_min_node_count = 6
          + logscale_ingress_node_count     = 18
          + logscale_ingress_resources      = {
              + limits   = {
                  + cpu    = 30
                  + memory = "122Gi"
                }
              + requests = {
                  + cpu    = 15
                  + memory = "122Gi"
                }
            }
          + logscale_ingress_root_disk_size = 128
          + logscale_ingress_root_disk_type = "pd-ssd"
          + logscale_ui_data_disk_size      = "128Gi"
          + logscale_ui_machine_type        = "n2-standard-16"
          + logscale_ui_max_node_count      = 6
          + logscale_ui_min_node_count      = 3
          + logscale_ui_node_count          = 9
          + logscale_ui_resources           = {
              + limits   = {
                  + cpu    = 30
                  + memory = "122Gi"
                }
              + requests = {
                  + cpu    = 30
                  + memory = "122Gi"
                }
            }
          + logscale_ui_root_disk_size      = 128
          + logscale_ui_root_disk_type      = "pd-ssd"
          + zookeeper_data_disk_size        = "64Gi"
          + zookeeper_machine_type          = "e2-standard-4"
          + zookeeper_max_node_count        = 3
          + zookeeper_min_node_count        = 1
          + zookeeper_node_count            = 2
          + zookeeper_resources             = {
              + limits   = {
                  + cpu    = 3
                  + memory = "8Gi"
                }
              + requests = {
                  + cpu    = 1
                  + memory = "8Gi"
                }
            }
          + zookeeper_root_disk_size        = 64
          + zookeeper_root_disk_type        = "pd-ssd"
        }
      + xsmall = {
          + kafka_broker_data_disk_size     = "152Gi"
          + kafka_broker_machine_type       = "e2-standard-4"
          + kafka_broker_max_node_count     = 3
          + kafka_broker_min_node_count     = 1
          + kafka_broker_node_count         = 3
          + kafka_broker_resources          = {
              + limits   = {
                  + cpu    = 3
                  + memory = "12Gi"
                }
              + requests = {
                  + cpu    = 3
                  + memory = "12Gi"
                }
            }
          + kafka_broker_root_disk_size     = 128
          + kafka_broker_root_disk_type     = "pd-ssd"
          + logscale_digest_data_disk_size  = "3000Gi"
          + logscale_digest_local_ssd_count = 8
          + logscale_digest_machine_type    = "n2-standard-16"
          + logscale_digest_max_node_count  = 3
          + logscale_digest_min_node_count  = 1
          + logscale_digest_node_count      = 3
          + logscale_digest_resources       = {
              + limits   = {
                  + cpu    = 7
                  + memory = "30Gi"
                }
              + requests = {
                  + cpu    = 7
                  + memory = "30Gi"
                }
            }
          + logscale_digest_root_disk_size  = 128
          + logscale_digest_root_disk_type  = "pd-ssd"
          + logscale_ingest_data_disk_size  = "128Gi"
          + logscale_ingest_machine_type    = "e2-standard-4"
          + logscale_ingest_max_node_count  = 3
          + logscale_ingest_min_node_count  = 1
          + logscale_ingest_node_count      = 3
          + logscale_ingest_resources       = {
              + limits   = {
                  + cpu    = 3
                  + memory = "12Gi"
                }
              + requests = {
                  + cpu    = 3
                  + memory = "12Gi"
                }
            }
          + logscale_ingest_root_disk_size  = 128
          + logscale_ingest_root_disk_type  = "pd-ssd"
          + logscale_ingress_data_disk_size = "128Gi"
          + logscale_ingress_machine_type   = "n2-standard-8"
          + logscale_ingress_max_node_count = 3
          + logscale_ingress_min_node_count = 1
          + logscale_ingress_node_count     = 3
          + logscale_ingress_resources      = {
              + limits   = {
                  + cpu    = 7
                  + memory = "12Gi"
                }
              + requests = {
                  + cpu    = 7
                  + memory = "12Gi"
                }
            }
          + logscale_ingress_root_disk_size = 128
          + logscale_ingress_root_disk_type = "pd-ssd"
          + logscale_ui_data_disk_size      = "128Gi"
          + logscale_ui_machine_type        = "e2-standard-4"
          + logscale_ui_max_node_count      = 3
          + logscale_ui_min_node_count      = 1
          + logscale_ui_node_count          = 3
          + logscale_ui_resources           = {
              + limits   = {
                  + cpu    = 3
                  + memory = "12Gi"
                }
              + requests = {
                  + cpu    = 3
                  + memory = "12Gi"
                }
            }
          + logscale_ui_root_disk_size      = 128
          + logscale_ui_root_disk_type      = "pd-ssd"
          + zookeeper_data_disk_size        = "64Gi"
          + zookeeper_machine_type          = "e2-standard-4"
          + zookeeper_max_node_count        = 3
          + zookeeper_min_node_count        = 1
          + zookeeper_node_count            = 3
          + zookeeper_resources             = {
              + limits   = {
                  + cpu    = 3
                  + memory = "8Gi"
                }
              + requests = {
                  + cpu    = 1
                  + memory = "8Gi"
                }
            }
          + zookeeper_root_disk_size        = 64
          + zookeeper_root_disk_type        = "pd-ssd"
        }
    }
  + logscale_cluster_identifier    = (known after apply)
  + logscale_cluster_name          = (known after apply)
  + logscale_cluster_project_id    = "formidable-pact-398819"
  + logscale_cluster_region        = "us-central1"
  + logscale_cluster_size          = "xsmall"
  + logscale_cluster_type          = "basic"
  + logscale_cluster_zone          = "us-central1-a"
  + logscale_gce_ingress_ip        = (known after apply)
  + network_id                     = (known after apply)
  + network_name                   = (known after apply)
  + subnetwork_id                  = (known after apply)
